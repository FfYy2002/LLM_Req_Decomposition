# -*- coding: utf-8 -*-
"""
AR æ¸…æ´—è„šæœ¬ï¼ˆLLM åˆ¤æ–­ + è‡ªåŠ¨åˆ é™¤æ€»ç»“å°¾å¥ï¼‰

åŠŸèƒ½ï¼š
- è¯»å– ar_output/ar_extracted_requirements_*.xlsx
- è‡ªåŠ¨ç§»é™¤ AR ä¸­çš„æ€»ç»“æ€§å°¾å¥ï¼ˆå¦‚â€œç»¼ä¸Šæ‰€è¿°â€ã€â€œä»¥ä¸Šæ˜¯...â€ï¼‰
- è°ƒç”¨ LLM åˆ¤æ–­æ¸…æ´—åçš„å†…å®¹æ˜¯å¦åˆè§„ï¼ˆä»…æ£€æŸ¥ï¼šç¼–å·æ ¼å¼ã€æ— åé—®ã€æ— æˆªæ–­ï¼‰ï¼Œä»…ä¿ç•™ AR_é«˜çº§éœ€æ±‚ å’Œ AR_ç»†èŠ‚éœ€æ±‚ éƒ½åˆè§„çš„è¡Œ
- è¾“å‡ºåˆ° clean_ar_output/

ä½œè€…ï¼šminefan
æ—¥æœŸï¼š2025å¹´12æœˆ10æ—¥
"""

import os
import pandas as pd
from openai import OpenAI
import time
import threading
import re

# =============================================================================
# é…ç½®
# =============================================================================
INPUT_DIR = "ar_output"
OUTPUT_DIR = "clean_ar_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    raise EnvironmentError(
        "âŒ ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æœªè®¾ç½®ã€‚\n"
        "è¯·åœ¨è¿è¡Œå‰æ‰§è¡Œï¼š\n"
        "  Windows (PowerShell): $env:DASHSCOPE_API_KEY='sk-xxx'\n"
        "  Linux/macOS: export DASHSCOPE_API_KEY='sk-xxx'"
    )

CLIENT = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

MAX_CONCURRENT = 6
semaphore = threading.Semaphore(MAX_CONCURRENT)


# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼šç§»é™¤æ€»ç»“æ€§å°¾å¥
# =============================================================================
def remove_summary_tail(text: str) -> str:
    if not text or pd.isna(text):
        return text
    s = str(text).strip()
    lines = s.split('\n')
    cleaned_lines = []

    # æ€»ç»“å…³é”®è¯ï¼ˆä¸å«â€œè¯´æ˜ï¼šâ€ï¼‰
    summary_patterns = [
        r"ç»¼ä¸Šæ‰€è¿°[ï¼Œã€‚:ï¼š]*",
        r"ä»¥ä¸Š.*å¼€å‘éœ€æ±‚[ï¼Œã€‚]*",
        r"ä»¥ä¸Š.*å†…å®¹[ï¼Œã€‚]*",
        r"ä¸Šè¿°.*éœ€æ±‚[ï¼Œã€‚]*",
        r"æ€»çš„æ¥è¯´[ï¼Œã€‚]*",
        r"å› æ­¤ï¼Œ.*$",
        r"æ•….*$",
        r"æœ€ç»ˆ.*$",
        r"ï¼ˆå®Œï¼‰",
        r"ã€ç»“æŸã€‘",
        r"è¾“å‡ºç»“æŸ",
        r"ç”Ÿæˆå®Œæ¯•",
        r"ä»¥ä¸Šå³ä¸º.*",
        r"å¦‚ä¸Šæ‰€è¿°.*"
    ]

    # ä»åå¾€å‰æ‰«æï¼Œè·³è¿‡æ€»ç»“å¥
    skip = True
    for line in reversed(lines):
        stripped = line.strip()
        is_summary = any(re.search(pat, stripped, re.IGNORECASE) for pat in summary_patterns)
        if skip and is_summary:
            continue
        else:
            skip = False
            cleaned_lines.append(line)

    result = '\n'.join(reversed(cleaned_lines)).strip()
    return result if result else s


# =============================================================================
# LLM åˆè§„åˆ¤æ–­ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„ä¸¥æ ¼æç¤ºè¯ï¼‰
# =============================================================================
VALIDATION_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„éœ€æ±‚å·¥ç¨‹è´¨æ£€å‘˜ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹â€œå¼€å‘éœ€æ±‚â€æ–‡æœ¬æ˜¯å¦å®Œå…¨ç¬¦åˆ ARï¼ˆAcceptance Requirementï¼‰è§„èŒƒã€‚

ã€AR è§„èŒƒç¡¬æ€§è¦æ±‚ã€‘
1. å¿…é¡»æ˜¯ä»¥é˜¿æ‹‰ä¼¯æ•°å­—åŠ ç‚¹å¼€å¤´çš„ç¼–å·åˆ—è¡¨ï¼ˆå¦‚ "1. ..."ï¼‰ï¼Œè‡³å°‘åŒ…å« 2 é¡¹ã€‚
2. å†…å®¹å¿…é¡»å®Œæ•´ï¼Œä¸èƒ½è¢«æˆªæ–­ï¼ˆå¦‚ç»“å°¾æ˜¯é€—å·ã€å†’å·ã€çœç•¥å·æˆ–åŠå¥è¯ï¼‰ã€‚
3. âŒ ç»å¯¹ç¦æ­¢å‡ºç°ä»¥ä¸‹ä»»ä½•æƒ…å†µï¼š
   - è¯·æ±‚ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šâ€œè¯·æä¾›...â€ã€â€œéœ€è¦æ›´è¯¦ç»†çš„éœ€æ±‚â€ï¼‰
   - è¡¨ç¤ºå› ä¿¡æ¯ä¸è¶³æ— æ³•ç”Ÿæˆï¼ˆä¾‹å¦‚ï¼šâ€œç”±äºæœªæä¾›...â€ã€â€œæ— æ³•ç¡®å®š...â€ï¼‰
   - ä½¿ç”¨åé—®æˆ–ç–‘é—®è¯­æ°”ï¼ˆå³ä½¿æ²¡æœ‰é—®å·ï¼‰
   - å‡ºç°â€œä¸æ¸…æ¥šâ€ã€â€œä¸ç¡®å®šâ€ã€â€œå»ºè®®è¡¥å……â€ç­‰æ¨è¯¿æ€§è¡¨è¿°

ã€åˆ¤æ–­è§„åˆ™ã€‘
- åªè¦å­˜åœ¨ä¸Šè¿°ä»»ä¸€è¿è§„ï¼Œå³ä¸ºâ€œä¸åˆè§„â€ã€‚
- å³ä½¿å†…å®¹çœ‹èµ·æ¥â€œåˆç†â€æˆ–â€œç¤¼è²Œâ€ï¼Œåªè¦åŒ…å«è¯·æ±‚/æ¨è¯¿/ä¸ç¡®å®šè¯­ä¹‰ï¼Œå°±æ˜¯ä¸åˆè§„ã€‚
- ä¸è¦åŒæƒ…ï¼Œä¸è¦å®½å®¹ï¼ŒåªæŒ‰è§„åˆ™åˆ¤æ–­ã€‚

è¯·ä»…å›ç­”ä¸€ä¸ªè¯ï¼š"åˆè§„" æˆ– "ä¸åˆè§„"ï¼Œä¸è¦è§£é‡Šã€ä¸è¦åŠ æ ‡ç‚¹ã€ä¸è¦æ¢è¡Œã€‚

å¼€å‘éœ€æ±‚æ–‡æœ¬ï¼š
{ar_text}
"""


def is_ar_valid_by_llm(ar_text: str, max_retries=2) -> bool:
    if not ar_text or pd.isna(ar_text):
        return False

    # å…ˆç§»é™¤æ€»ç»“å°¾å¥ï¼ˆé¢„å¤„ç†ï¼‰
    cleaned_text = remove_summary_tail(ar_text)
    if not cleaned_text.strip():
        return False

    prompt = VALIDATION_PROMPT.format(ar_text=cleaned_text.strip()[:1500])

    for attempt in range(max_retries + 1):
        try:
            with semaphore:  # é™åˆ¶å¹¶å‘
                response = CLIENT.chat.completions.create(
                    model="qwen-plus",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.0,
                    timeout=15
                )
            answer = response.choices[0].message.content.strip()
            return "åˆè§„" in answer
        except Exception as e:
            if attempt >= max_retries:
                print(f"[WARN] LLM åˆ¤æ–­å¤±è´¥ï¼Œè§†ä¸ºä¸åˆè§„ | åŸå› : {e}")
                return False
            time.sleep(1)
    return False


# =============================================================================
# å¤„ç†å•ä¸ªæ–‡ä»¶
# =============================================================================
def clean_file(filepath):
    df = pd.read_excel(filepath)
    total = len(df)
    print(f"  â†’ æ­£åœ¨æ ¡éªŒ {total} è¡Œ...")

    valid_rows = []
    for idx, row in df.iterrows():
        ar_high = row["AR_é«˜çº§éœ€æ±‚"]
        ar_low = row["AR_ç»†èŠ‚éœ€æ±‚"]

        valid_high = is_ar_valid_by_llm(ar_high)
        valid_low = is_ar_valid_by_llm(ar_low)

        if valid_high and valid_low:
            # ä¿å­˜çš„æ˜¯ å·²æ¸…æ´—æ€»ç»“å°¾å¥ çš„ç‰ˆæœ¬
            valid_rows.append({
                "åŸå§‹_é«˜çº§éœ€æ±‚": row["åŸå§‹_é«˜çº§éœ€æ±‚"],
                "AR_é«˜çº§éœ€æ±‚": remove_summary_tail(ar_high),
                "åŸå§‹_ç»†èŠ‚éœ€æ±‚": row["åŸå§‹_ç»†èŠ‚éœ€æ±‚"],
                "AR_ç»†èŠ‚éœ€æ±‚": remove_summary_tail(ar_low),
            })

        if (idx + 1) % 20 == 0:
            print(f"    å·²å¤„ç† {idx+1}/{total}")

    return pd.DataFrame(valid_rows)


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================
def main():
    files = [
        os.path.join(INPUT_DIR, f)
        for f in os.listdir(INPUT_DIR)
        if f.startswith("ar_extracted_requirements_") and f.endswith(".xlsx")
    ]

    if not files:
        print(f"[!] åœ¨ {INPUT_DIR} ä¸­æœªæ‰¾åˆ° AR æ–‡ä»¶")
        return

    print(f"[INFO] å…± {len(files)} ä¸ªæ–‡ä»¶å¾…æ¸…æ´—")

    for fp in files:
        try:
            base = os.path.basename(fp)
            cleaned_df = clean_file(fp)
            out_path = os.path.join(OUTPUT_DIR, "clean_" + base)
            cleaned_df.to_excel(out_path, index=False, engine="openpyxl")
            original_count = len(pd.read_excel(fp))
            print(f"âœ… {base} â†’ ä¿ç•™ {len(cleaned_df)} / {original_count} è¡Œ")
        except Exception as e:
            print(f"[SKIP] {fp} | é”™è¯¯: {e}")

    print(f"\nğŸ‰ æ¸…æ´—å®Œæˆï¼Œç»“æœä¿å­˜è‡³ '{OUTPUT_DIR}'")


if __name__ == "__main__":
    main()